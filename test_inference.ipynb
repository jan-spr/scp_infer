{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer causal Structure on ScanPy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure:\n",
    "A: Load Data from file & look at structure\n",
    "\n",
    "B: Algorithms\n",
    "1. GRNBoost2\n",
    "2. GIES\n",
    "3. DCDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies:\n",
    " use a conda-env with:\n",
    " - scanpy python-igraph leidenalg\n",
    "\n",
    " GRNBoost:\n",
    " - conda install -c bioconda arboreto\n",
    " \n",
    " GIES:\n",
    " - pip install gies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scp_infer as scpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_file = '../data/edited/Schraivogel_chr8_ad-scaled_10gene.h5ad'  # the file that will store the analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what count distribution looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st step: extract data matrix, gene names and cell names from the AnnData object\n",
    "gene_names = adata.var_names\n",
    "cell_names = adata.obs_names\n",
    "\n",
    "#print(\"Data matrix shape: \", df.shape)\n",
    "#print(\"sample: \", df.iloc[0:3,0:3])\n",
    "print(len(gene_names),\"genes: \", [i for i in gene_names[:3]])\n",
    "print(len(cell_names),\"cells: \", [i for i in cell_names[:1]])\n",
    "\n",
    "#2nd step: extract metadata from the AnnData object and exctract perturbation information\n",
    "metadata = adata.obs\n",
    "metadata.head()\n",
    "\n",
    "# Look at more perturbation labels\n",
    "# print(adata.obs['perturbation'].astype(str).copy()[1000:1020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([i for i in adata.var['mean'][0:10]])\n",
    "# print([i for i in adata.var['std'][0:10]])\n",
    "# print corresponding perturbation labels\n",
    "print('Perturbations: ', [i for i in adata.obs['perturbation'][:10]])\n",
    "\n",
    "scpi.adata.print_expression_mean_std(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GRNBoost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_GRNBoost = False\n",
    "if run_GRNBoost:\n",
    "    grnb = scpi.inference.grnboost2.GRNBoost2Imp(adata, verbose= True)\n",
    "    grnb.convert_data()\n",
    "    grnb.infer(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reshape Count matrix\n",
    "2. Run GIES\n",
    "\n",
    "\n",
    "GIES Matrix Format - collected by intervention locations :\n",
    "- data: n_interventions x n_samples/intervention (->take min.) x n_variables\n",
    "- Intervention: 1 x n_intervention\n",
    "\n",
    "Data Distribution:\n",
    "- scale to mean 0 & std 1\n",
    "\n",
    "-> intervened values <<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_GIES = True\n",
    "data_GIES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if run_GIES or data_GIES:\n",
    "    gies_imp = scpi.inference.gies.GIESImp(adata, verbose= True)\n",
    "    gies_imp.convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the data if it should be used externally\n",
    "if data_GIES:\n",
    "    np.save(\"./data/temp/gies_data_matrix.npy\", gies_imp.data_matrix)\n",
    "\n",
    "    import json\n",
    "\n",
    "    with open(\"./data/temp/gies_intervention_list.json\", 'w') as f:\n",
    "        # indent=2 is not needed but makes the file human-readable \n",
    "        # if the data is nested\n",
    "        json.dump(gies_imp.intervention_list, f, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run GIES\n",
    "if run_GIES:\n",
    "    estimate, score = gies_imp.infer(plot=True)\n",
    "    print(estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DCDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_DCDI = False\n",
    "if run_DCDI:\n",
    "    import os\n",
    "    import argparse\n",
    "    import cdt\n",
    "    import torch\n",
    "    import numpy as np\n",
    "\n",
    "    import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_DCDI:\n",
    "    current_dir = os.path.abspath(\".\")\n",
    "\n",
    "    print(\"Current dir: \", current_dir)\n",
    "    sys.path.append(os.path.join(current_dir, 'dcdi_implementation'))\n",
    "    sys.path.append(os.path.join(current_dir, 'dcdi_implementation/dcdi_master/dcdi'))\n",
    "\n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_DCDI:\n",
    "    import dcdi_master as dcdi\n",
    "    from dcdi_master.dcdi.models.learnables import LearnableModel_NonLinGaussANM\n",
    "    from dcdi_master.dcdi.models.flows import DeepSigmoidalFlowModel\n",
    "    from dcdi_master.dcdi.train import train, retrain, compute_loss\n",
    "    from dcdi_master.dcdi.data import DataManagerFile\n",
    "    from dcdi_master.dcdi.utils.save import dump\n",
    "\n",
    "    from dcdi_load import DataManagerAnndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_metrics(stage, step, metrics, throttle=None):\n",
    "    for k, v in metrics.items():\n",
    "        print(\"    %s:\" % k, v)\n",
    "\n",
    "def file_exists(prefix, suffix):\n",
    "    return os.path.exists(os.path.join(prefix, suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_DCDI:\n",
    "    \"\"\"\n",
    "    Parameters for the DCDI algorithm\n",
    "\n",
    "    store parameters as attributes of opt\n",
    "    \"\"\"\n",
    "\n",
    "    opt = argparse.Namespace()\n",
    "    # experiment\n",
    "    opt.exp_path = './dcdi_implementation/exp_10genes_100k'  # Path to experiments\n",
    "    opt.train = True            # Run `train` function, get /train folder\n",
    "    opt.retrain = False         # after to-dag or pruning, retrain model from scratch before reporting nll-val\n",
    "    opt.dag_for_retrain = None  # path to a DAG in .npy format which will be used for retrainig. e.g.  /code/stuff/DAG.npy\n",
    "    opt.random_seed = 42        # Random seed for pytorch and numpy\n",
    "\n",
    "    # data\n",
    "    opt.data_path = None        # Path to data files\n",
    "    opt.i_dataset = None        # dataset index\n",
    "    opt.num_vars = len(adata.var_names)            # Number of variables\n",
    "    opt.train_samples = 0.8     # Number of samples used for training (default is 80% of the total size)\n",
    "    opt.test_samples = None     # Number of samples used for testing (default is whatever is not used for training)\n",
    "    opt.num_folds = 5           # number of folds for cross-validation\n",
    "    opt.fold = 0                # fold we should use for testing\n",
    "    opt.train_batch_size = 64   # number of samples in a minibatch\n",
    "    opt.num_train_iter = 1000000 # number of meta gradient steps\n",
    "    opt.normalize_data = False  # (x - mu) / std\n",
    "    opt.regimes_to_ignore = None # When loading data, will remove some regimes from data set\n",
    "    opt.test_on_new_regimes = False # When using --regimes-to-ignore, we evaluate performance on new regimes never seen during training (use after retraining).\n",
    "\n",
    "    # model\n",
    "    opt.model = 'DCDI-G'        # model class (DCDI-G or DCDI-DSF)\n",
    "    opt.num_layers = 2          # number of hidden layers\n",
    "    opt.hid_dim = 16            # number of hidden units per layer\n",
    "    opt.nonlin = 'leaky-relu'   # leaky-relu | sigmoid\n",
    "    opt.flow_num_layers = 2     # number of hidden layers of the DSF\n",
    "    opt.flow_hid_dim = 16       # number of hidden units of the DSF\n",
    "\n",
    "    # intervention  \n",
    "    opt.intervention = True     # Use data with intervention\n",
    "    opt.dcd = False             # Use DCD (DCDI with a loss not taking into account the intervention)\n",
    "    opt.intervention_type = \"imperfect\" # Type of intervention: perfect or imperfect\n",
    "    opt.intervention_knowledge = \"known\" # If the targets of the intervention are known or unknown\n",
    "    opt.coeff_interv_sparsity = 1e-8 # Coefficient of the regularisation in the unknown interventions case (lambda_R)\n",
    "\n",
    "    # optimization\n",
    "    opt.optimizer = \"rmsprop\"   # sgd|rmsprop\n",
    "    opt.lr = 1e-3               # learning rate for optim\n",
    "    opt.lr_reinit = None        # Learning rate for optim after first subproblem. Default mode reuses --lr.\n",
    "    opt.lr_schedule = None      # Learning rate for optim, change initial lr as a function of mu: None|sqrt-mu|log-mu\n",
    "    opt.stop_crit_win = 100     # window size to compute stopping criterion\n",
    "    opt.reg_coeff = 0.1         # regularization coefficient (lambda)\n",
    "\n",
    "    # Augmented Lagrangian options\n",
    "    opt.omega_gamma = 1e-4      # Precision to declare convergence of subproblems\n",
    "    opt.omega_mu = 0.9          # After subproblem solved, h should have reduced by this ratio\n",
    "    opt.mu_init = 1e-8          # initial value of mu\n",
    "    opt.mu_mult_factor = 2      # Multiply mu by this amount when constraint not sufficiently decreasing\n",
    "    opt.gamma_init = 0.         # initial value of gamma\n",
    "    opt.h_threshold = 1e-8      # Stop when |h|<X. Zero means stop AL procedure only when h==0\n",
    "\n",
    "    # misc\n",
    "    opt.patience = 10           # Early stopping patience in --retrain.\n",
    "    opt.train_patience = 5      # Early stopping patience in --train after constraint\n",
    "    opt.train_patience_post = 5 # Early stopping patience in --train after threshold\n",
    "\n",
    "    # logging\n",
    "    opt.plot_freq = 100       # plotting frequency\n",
    "    opt.no_w_adjs_log = False   # do not log weighted adjacency (to save RAM). One plot will be missing (A_\\phi plot)\n",
    "    opt.plot_density = False    # Plot density (only implemented for 2 vars)\n",
    "\n",
    "    # device and numerical precision\n",
    "    opt.gpu = True              # Use GPU\n",
    "    opt.float = False           # Use Float precision\n",
    "\n",
    "    plotting_callback = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if run_DCDI:\n",
    "    # Control as much randomness as possible\n",
    "    torch.manual_seed(opt.random_seed)\n",
    "    np.random.seed(opt.random_seed)\n",
    "\n",
    "    if opt.lr_reinit is not None:\n",
    "        assert opt.lr_schedule is None, \"--lr-reinit and --lr-schedule are mutually exclusive\"\n",
    "\n",
    "    # Initialize metric logger if needed\n",
    "    metrics_callback = _print_metrics\n",
    "\n",
    "    # adjust some default hparams\n",
    "    if opt.lr_reinit is None: opt.lr_reinit = opt.lr\n",
    "\n",
    "    # Use GPU\n",
    "    if opt.gpu:\n",
    "        if opt.float:\n",
    "            torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        else:\n",
    "            torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "    else:\n",
    "        if opt.float:\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "        else:\n",
    "            torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # create DataManager for training\n",
    "    train_data = DataManagerAnndata(opt.data_path, adata, opt.train_samples, opt.test_samples, train=True,\n",
    "                                    normalize=opt.normalize_data,\n",
    "                                    random_seed=opt.random_seed,\n",
    "                                    intervention=opt.intervention,\n",
    "                                    intervention_knowledge=opt.intervention_knowledge,\n",
    "                                    dcd=opt.dcd)\n",
    "    test_data = DataManagerAnndata(opt.data_path, adata, opt.train_samples, opt.test_samples, train=False,\n",
    "                                normalize=opt.normalize_data, mean=train_data.mean, std=train_data.std,\n",
    "                                random_seed=opt.random_seed,\n",
    "                                intervention=opt.intervention,\n",
    "                                intervention_knowledge=opt.intervention_knowledge,\n",
    "                                dcd=opt.dcd)\n",
    "\n",
    "    # create learning model and ground truth model\n",
    "    if opt.model == \"DCDI-G\":\n",
    "        model = LearnableModel_NonLinGaussANM(opt.num_vars,\n",
    "                                                opt.num_layers,\n",
    "                                                opt.hid_dim,\n",
    "                                                nonlin=opt.nonlin,\n",
    "                                                intervention=opt.intervention,\n",
    "                                                intervention_type=opt.intervention_type,\n",
    "                                                intervention_knowledge=opt.intervention_knowledge,\n",
    "                                                num_regimes=train_data.num_regimes)\n",
    "    elif opt.model == \"DCDI-DSF\":\n",
    "        model = DeepSigmoidalFlowModel(num_vars=opt.num_vars,\n",
    "                                        cond_n_layers=opt.num_layers,\n",
    "                                        cond_hid_dim=opt.hid_dim,\n",
    "                                        cond_nonlin=opt.nonlin,\n",
    "                                        flow_n_layers=opt.flow_num_layers,\n",
    "                                        flow_hid_dim=opt.flow_hid_dim,\n",
    "                                        intervention=opt.intervention,\n",
    "                                        intervention_type=opt.intervention_type,\n",
    "                                        intervention_knowledge=opt.intervention_knowledge,\n",
    "                                        num_regimes=train_data.num_regimes)\n",
    "    else:\n",
    "        raise ValueError(\"opt.model has to be in {DCDI-G, DCDI-DSF}\")\n",
    "\n",
    "    # print device of samples, masks and regimes\n",
    "    print(\"train_data.adjacency.device:\", train_data.adjacency.device)\n",
    "    print(\"train_data.asmples.device:\", train_data.gt_interv.device)\n",
    "    #print(\"train_data.regimes.device:\", train_data.regimes.device)\n",
    "\n",
    "\n",
    "\n",
    "    # train until constraint is sufficiently close to being satisfied\n",
    "    if opt.train:\n",
    "        train(model, train_data.adjacency.detach().cpu().numpy(),\n",
    "                train_data.gt_interv, train_data, test_data, opt, metrics_callback,\n",
    "                plotting_callback)\n",
    "\n",
    "    elif opt.retrain:\n",
    "        initial_dag = np.load(opt.dag_for_retrain)\n",
    "        model.adjacency[:, :] = torch.as_tensor(initial_dag).type(torch.Tensor)\n",
    "        best_model = retrain(model, train_data, test_data, \"ignored_regimes\", opt, metrics_callback, plotting_callback)\n",
    "\n",
    "    # Evaluate on ignored regimes!\n",
    "    if opt.test_on_new_regimes:\n",
    "        all_regimes = train_data.all_regimes\n",
    "\n",
    "        # take all data, but ignore data on which we trained (want to test on unseen regime)\n",
    "        regimes_to_ignore = np.setdiff1d(all_regimes, np.array(opt.regimes_to_ignore))\n",
    "        new_data = DataManagerFile(opt.data_path, opt.i_dataset, 1., None, train=True,\n",
    "                                    normalize=opt.normalize_data,\n",
    "                                    random_seed=opt.random_seed,\n",
    "                                    intervention=opt.intervention,\n",
    "                                    intervention_knowledge=opt.intervention_knowledge,\n",
    "                                    dcd=opt.dcd,\n",
    "                                    regimes_to_ignore=regimes_to_ignore)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            weights, biases, extra_params = best_model.get_parameters(mode=\"wbx\")\n",
    "\n",
    "            # evaluate on train\n",
    "            x, masks, regimes = train_data.sample(train_data.num_samples)\n",
    "            loss_train, mean_std_train = compute_loss(x, masks, regimes, best_model, weights, biases, extra_params,\n",
    "                                                    intervention=True, intervention_type='structural',\n",
    "                                                    intervention_knowledge=\"known\", mean_std=True)\n",
    "\n",
    "            # evaluate on valid\n",
    "            x, masks, regimes = test_data.sample(test_data.num_samples)\n",
    "            loss_test, mean_std_test = compute_loss(x, masks, regimes, best_model, weights, biases, extra_params,\n",
    "                                                    intervention=True, intervention_type='structural',\n",
    "                                                    intervention_knowledge=\"known\", mean_std=True)\n",
    "\n",
    "            # evaluate on new intervention\n",
    "            x, masks, regimes = new_data.sample(new_data.num_samples)\n",
    "            loss_new, mean_std_new = compute_loss(x, masks, regimes, best_model, weights, biases, extra_params,\n",
    "                                                    intervention=True, intervention_type='structural',\n",
    "                                                    intervention_knowledge=\"known\", mean_std=True)\n",
    "\n",
    "            # logging final result\n",
    "            metrics_callback(stage=\"test_on_new_regimes\", step=0,\n",
    "                                metrics={\"log_likelihood_train\": - loss_train.item(),\n",
    "                                        \"mean_std_train\": mean_std_train.item(),\n",
    "                                        \"log_likelihood_test\": - loss_test.item(),\n",
    "                                        \"mean_std_test\": mean_std_test.item(),\n",
    "                                        \"log_likelihood_new\": - loss_new.item(),\n",
    "                                        \"mean_std_new\": mean_std_new.item()}, throttle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_DCDI:\n",
    "    DCDI_matrix =model.adjacency.detach().cpu().numpy()\n",
    "    print(np.shape(DCDI_matrix))\n",
    "    print(DCDI_matrix)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig1 = ax.matshow(DCDI_matrix)\n",
    "    plt.colorbar(fig1)\n",
    "    plt.title(\"DCDI: Adjacency matrix\")\n",
    "    plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-infer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
